{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing functions\n",
    "\n",
    "This includes\n",
    "- Converting dates to timestamps\n",
    "- Calculating all the Gustas things for the previous _n_ games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = {\n",
    "    \"GoalsFullTime\": (\"FTHG\", \"FTAG\"),\n",
    "    \"GoalsHalfTime\": (\"HTHG\", \"HTAG\"),\n",
    "    \"GustasPoints\":  (\"HomePoints\", \"AwayPoints\"),\n",
    "    \"GoalShots\":     (\"HS\",   \"AS\"),\n",
    "    \"TargetShots\":   (\"HST\",  \"AST\"),\n",
    "    \"Corners\":       (\"HC\",   \"AC\"),\n",
    "    \"YellowCards\":   (\"HY\",   \"AY\"),\n",
    "    \"RedCards\":      (\"HR\",   \"AR\")\n",
    "}\n",
    "\n",
    "\n",
    "def create_date_stamp(date_string: str) -> int:\n",
    "    # Transforms a dd/mm/yy or dd/mm/yyyy string to a timestamp\n",
    "    if len(date_string.split(\"/\")[-1]) == 4:\n",
    "        return int(datetime.strptime(date_string, \"%d/%m/%Y\").timestamp())\n",
    "    else:\n",
    "        return int(datetime.strptime(date_string, \"%d/%m/%y\").timestamp())\n",
    "\n",
    "\n",
    "def group_seasons(df: pd.DataFrame) -> np.array:\n",
    "    # Adds a column to the df indicating which season it is\n",
    "    seasons = []\n",
    "    season_counter = 1\n",
    "    prev_season_index = 0\n",
    "    rows = df.iterrows()\n",
    "    next(rows)\n",
    "\n",
    "    for i, game in rows:\n",
    "        if game.Date[4] == \"8\" and df.iloc[i - 1].Date[4] == \"5\":\n",
    "            seasons += [season_counter]*(i - prev_season_index)\n",
    "            season_counter += 1\n",
    "            prev_season_index = i\n",
    "\n",
    "    return pd.DataFrame({\"Season\": seasons})\n",
    "\n",
    "\n",
    "def generate_gustas_points(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Caluclate Gustas' points for each game\n",
    "    points = {\"HomePoints\": [0]*len(df), \"AwayPoints\": [0]*len(df)}\n",
    "    score_map = {\"H\": (3, 0), \"A\": (0, 3), \"D\": (1, 1)}\n",
    "\n",
    "    for i, (_, game) in enumerate(df.iterrows()):\n",
    "        points[\"HomePoints\"][i], points[\"AwayPoints\"][i] = score_map[game[\"FTR\"]]\n",
    "\n",
    "    return pd.DataFrame(points)\n",
    "            \n",
    "\n",
    "def calculate_season_metrics(df: pd.DataFrame, teams: [str], metric: str) -> pd.DataFrame:\n",
    "    # Translates metrics from home-away data to team data\n",
    "    # The df will be across an entire season\n",
    "    global METRICS\n",
    "    metric_by_team = {}\n",
    "\n",
    "    for team in teams:\n",
    "        home_games = df[df[\"HomeTeam\"] == team]\n",
    "        away_games = df[df[\"AwayTeam\"] == team]\n",
    "        metric_by_team[team] = home_games[METRICS[metric][0]].sum() + away_games[METRICS[metric][1]].sum()\n",
    "\n",
    "    return metric_by_team\n",
    "\n",
    "\n",
    "def generate_previous_season_stats(curr: pd.DataFrame, prev: pd.DataFrame, teams: [str]) -> pd.DataFrame:\n",
    "    # Includes the metrics for the previous season in each game of the current\n",
    "    # args:\n",
    "    # - curr: the current season\n",
    "    # - prev: the previous season\n",
    "    # - teams: the list of all teams\n",
    "    # \n",
    "    # returns\n",
    "    # A dataframe whose columns are named 'HomePST{metric}' and 'AwayPST{metric}'\n",
    "    global METRICS\n",
    "    prev_season_metrics = { m : calculate_season_metrics(prev, teams, m) for m in METRICS }\n",
    "    metrics_df = {}\n",
    "\n",
    "    for metric in METRICS:\n",
    "        metrics_df[f\"HomePST{metric}\"] = []\n",
    "        metrics_df[f\"AwayPST{metric}\"] = []\n",
    "\n",
    "    for _, game in curr.iterrows():\n",
    "        home = game[\"HomeTeam\"]\n",
    "        away = game[\"AwayTeam\"]\n",
    "\n",
    "        for metric in METRICS:\n",
    "            metrics_df[f\"HomePST{metric}\"].append(prev_season_metrics[metric][home])\n",
    "            metrics_df[f\"AwayPST{metric}\"].append(prev_season_metrics[metric][away])\n",
    "\n",
    "    df = pd.DataFrame(metrics_df)\n",
    "    df.index = curr.index\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_previous_season_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Creates a dataframe that includes df and the stats from\n",
    "    # the previous season\n",
    "    new_df = None\n",
    "    teams = df[\"HomeTeam\"].unique()\n",
    "\n",
    "    for i in range(1, int(df[\"Season\"].max())):\n",
    "        curr = df[df[\"Season\"] == i]\n",
    "        prev = df[df[\"Season\"] == i - 1]\n",
    "        res = generate_previous_season_stats(curr, prev, teams)\n",
    "\n",
    "        if new_df is None:\n",
    "            new_df = res\n",
    "        else:\n",
    "            new_df = pd.concat([new_df, res])\n",
    "\n",
    "    return df.join(new_df)\n",
    "\n",
    "\n",
    "def format_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Applies all feature engineering etc that one could want\n",
    "    df[\"DateStamp\"] = df[\"Date\"].map(create_date_stamp)\n",
    "    df = df.join(group_seasons(df)).join(generate_gustas_points(df))\n",
    "\n",
    "    return combine_previous_season_stats(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features etc\n",
    "FEATURES = [\n",
    "    \"HomeTeam\",\n",
    "    \"AwayTeam\",\n",
    "    \"Referee\",\n",
    "    \"DateStamp\",\n",
    "    \"HomePSTGoalsFullTime\",\n",
    "    \"HomePSTGoalsHalfTime\",\n",
    "    \"HomePSTGustasPoints\",\n",
    "    \"HomePSTGoalShots\",\n",
    "    \"HomePSTTargetShots\",\n",
    "    \"HomePSTCorners\",\n",
    "    \"HomePSTYellowCards\",\n",
    "    \"HomePSTRedCards\",\n",
    "    \"AwayPSTGoalsFullTime\",\n",
    "    \"AwayPSTGoalsHalfTime\",\n",
    "    \"AwayPSTGustasPoints\",\n",
    "    \"AwayPSTGoalShots\",\n",
    "    \"AwayPSTTargetShots\",\n",
    "    \"AwayPSTCorners\",\n",
    "    \"AwayPSTYellowCards\",\n",
    "    \"AwayPSTRedCards\"\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\"HomeTeam\", \"AwayTeam\", \"Referee\"]\n",
    "\n",
    "TARGET_NAMES = [\"A\", \"D\", \"H\"] # for presenting data\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "df = format_df(pd.read_csv(\"data/epl-training.csv\").dropna())\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df[\"FTR\"] = df[\"FTR\"].astype(str)\n",
    "\n",
    "for ft in CATEGORICAL_FEATURES:\n",
    "    df[ft] = df[ft].astype(str)\n",
    "\n",
    "\n",
    "# Split X and y, training and testing\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[\"FTR\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "numerical_features = [f for f in FEATURES if f not in CATEGORICAL_FEATURES]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), CATEGORICAL_FEATURES)\n",
    "    ])\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create SVM model\n",
    "\n",
    "Specifically, we are going to fit our model to our data and then predict the testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(probability=False)\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get performance metrics\n",
    "\n",
    "We're going to print a classification report and print some graphs and charts now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'y_pred' parameter of classification_report must be an array-like or a sparse matrix. Got 3 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb Cell 10\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m evaluate_model(y_test, \u001b[39m3\u001b[39;49m, TARGET_NAMES)\n",
      "\u001b[1;32m/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_model\u001b[39m(y_test, y_pred, target_names):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(classification_report(y_test, y_pred, target_names\u001b[39m=\u001b[39;49mtarget_names))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     ConfusionMatrixDisplay\u001b[39m.\u001b[39mfrom_predictions(y_test, y_pred, display_labels\u001b[39m=\u001b[39mtarget_names)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/conrad/UCL/Modules/COMP0036-ML/Coursework/conrad.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n",
      "File \u001b[0;32m~/UCL/Modules/COMP0036-ML/Coursework/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:204\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m to_ignore \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    202\u001b[0m params \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 204\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    205\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39;49mfunc\u001b[39m.\u001b[39;49m\u001b[39m__qualname__\u001b[39;49m\n\u001b[1;32m    206\u001b[0m )\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n",
      "File \u001b[0;32m~/UCL/Modules/COMP0036-ML/Coursework/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:96\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'y_pred' parameter of classification_report must be an array-like or a sparse matrix. Got 3 instead."
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_test, y_pred, target_names):\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "evaluate_model(y_test, y_pred, TARGET_NAMES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
